#### Important links #################
1. https://chatgpt.com/share/676c5b28-7334-8004-b573-e6a4c61ade23
2. https://chatgpt.com/c/6769ac71-f704-8004-a4df-92efafe5043e
3. https://chatgpt.com/c/676b9428-07e4-8004-af38-e7102a4b0c0b


######### To run this project what you need to do ########

1. Clone the repository
2. Run "docker compose build"
3. Run "docker compose up -d"
If error occurred empty data folder and rerun the mentioned command  above.

############# how fluentd process logs to elasticsearch ############

1. Fluentd is a log collector. it collects logs from volume, store to elasticsearch
####### working process ###########
1. Applications logs store in a shared volume
         1. docker volume ls   (check volume names)
         2. docker inspect container ( check the "mount" object to check volume is properly mounted or created)

               "Mounts": [
                   {
                       "Type": "volume",
                       "Name": "es-data",
                       "Source": "/var/lib/docker/volumes/es-data/_data",
                       "Destination": "/usr/share/elasticsearch/data",
                       "Driver": "local",
                       "Mode": "",
                       "RW": true,
                       "Propagation": ""
                   }
               ]
         3. docker volume inspect "volume_name" output will be like -
                 [
                   {
                     "CreatedAt": "2024-12-25T10:45:00Z",
                     "Driver": "local",
                     "Labels": {},
                     "Mountpoint": "/var/lib/docker/volumes/my_volume/_data",
                     "Name": "my_volume",
                     "Options": {},
                     "Scope": "local"
                   }
                 ]
        4. cd /var/lib/docker/volumes/my_volume/_data (access volume data on host)
        5. docker volume rm "volume_name" (remove docker volume)
        6. docker volume prune ( remove unused volume -> volumes that are not associated with any container)

2. Prepare the fluent.conf file so that it can read logs from container
3. Use writable folder to pos of logs like -> tmp
4. Check docker volume has proper permission or not ?
5. Check fluent-plugin-elasticsearch plugin compatible with elasticsearch

############## Check point if fluentd cant not capture logs properly or not store logs in elasticsearch ###########

2. Prepare the fluent.conf file so that it can read logs from container
3. Use writable folder to pos of logs like -> tmp
4. Check docker volume has proper permission or not ?
5. Check fluent-plugin-elasticsearch plugin compatible with elasticsearch


## Elasticsearch crud curls:

1. Create index in elasticsearch

    # POST request to create a document

    curl -X POST "localhost:9200/my_index/_doc/1" -H 'Content-Type: application/json' -d'
    {
      "title": "Elasticsearch Introduction",
      "content": "This is an example document in Elasticsearch."
    }

2. Retrieve specific document from elasticsearch

   # GET request to retrieve a document by ID
   curl -X GET "localhost:9200/my_index/_doc/1"

3. Update document in elasticsearch

   # POST request to update a document
   curl -X POST "localhost:9200/my_index/_doc/1/_update" -H 'Content-Type: application/json' -d'
   {
     "doc": {
       "title": "Updated Elasticsearch Introduction"
     }
   }

4. Delete specific document from index in elasticsearch

   # DELETE request to remove a document by ID
   curl -X DELETE "localhost:9200/my_index/_doc/1"

5. Get specific index from elasticsearch

    curl -X GET "localhost:9200/my_index"

6. Delete specific index from elasticsearch

   # DELETE request to remove index
   curl -X DELETE "localhost:9200/my_index"

7. Search document within index by content

    ## This will search for documents that contain the word "Elasticsearch" in the content field.

    curl -X GET "localhost:9200/my_index/_search" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "match": {
          "content": "Elasticsearch"
        }
      }
    }

8. Create index with bulk document

    curl -X POST "localhost:9200/my_index/_bulk" -H 'Content-Type: application/json' -d'
    { "index": { "_id": 1 } }
    { "title": "Document 1", "content": "This is the first document." }
    { "index": { "_id": 2 } }
    { "title": "Document 2", "content": "This is the second document." }

9. Delete by query from elasticsearch

    ## This will delete all documents in my_index that contain the word "Elasticsearch" in the content field.

    curl -X POST "localhost:9200/my_index/_delete_by_query" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "match": {
          "content": "Elasticsearch"
        }
      }
    }

10. List all indexes from elasticsearch
    curl -X GET "localhost:9200/_cat/indices?v"

11. Health check api in elasticsearch
    curl -X GET "localhost:9200/_cluster/health?pretty"


### Recovery process #####

12. Check nodes status, usages, available space, total space
     ### status -> yellow/red means critical condition, green means safe zone ###

    curl --location 'http://localhost:9200/_cat/nodes?v=null&h=ip%2Cname%2Cdisk.used%2Cdisk.avail%2Cdisk.total%2Cdisk.percent'

13. Check all index status  usages, free space, available & total space

    curl --location 'http://localhost:9200/_cat/indices?v=null&s=store.size%3Adesc'

 14. Using ILM ( Index lifecycle management) delete logs for certain time period
     ### This ILM policy creates new indices every 7 days or when the index reaches 50 GB, and deletes indices older than 30 days.

    {
      "policy": {
        "phases": {
          "hot": {
            "actions": {
              "rollover": {
                "max_age": "7d",
                "max_size": "50gb"
              }
            }
          },
          "delete": {
            "min_age": "30d",
            "actions": {
              "delete": {}
            }
          }
        }
      }
    }
